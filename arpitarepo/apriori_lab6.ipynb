{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70974827-0ae1-4278-a36a-01b984281023",
      "metadata": {
        "id": "70974827-0ae1-4278-a36a-01b984281023",
        "outputId": "1c6d4b24-b1fd-450f-f432-b172027ee6a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0.3\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "print(pd.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Key Concepts**:\n",
        "## Frequent Itemsets:\n",
        "\n",
        "An itemset is a collection of one or more items.\n",
        "\n",
        "A frequent itemset is an itemset that appears in the dataset with a frequency greater than or equal to a specified threshold (minimum support).\n",
        "\n",
        "## Association Rules:\n",
        "\n",
        "Association rules describe relationships between items based on their co-occurrence in transactions.\n",
        "\n",
        "The rules are typically of the form \"If itemset X is present, then itemset Y is also likely to be present.\"\n",
        "\n",
        "# **How Apriori Works:**\n",
        "The Apriori algorithm uses a level-wise search strategy to discover frequent itemsets. The key idea is based on the Apriori property:\n",
        "\n",
        "Apriori Property:  If an itemset is frequent, then all of its subsets must also be frequent.\n",
        "\n",
        "The algorithm iteratively generates candidate itemsets of increasing size, prunes infrequent candidates, and continues until no more frequent itemsets can be found.\n",
        "\n",
        "# **Steps in Apriori Algorithm**:\n",
        "###Generate Candidate Itemsets:\n",
        "\n",
        "Start with frequent itemsets of size 1.\n",
        "Generate candidates of size k by joining frequent itemsets of size k-1.\n",
        "###Scan the Dataset:\n",
        "\n",
        "Count the support (frequency) of each candidate itemset in the dataset.\n",
        "Prune Infrequent Itemsets:\n",
        "\n",
        "Remove candidate itemsets that do not meet the minimum support threshold.\n",
        "###Repeat:\n",
        "\n",
        "Repeat the process with the remaining frequent itemsets until no more frequent itemsets can be found.\n",
        "#**Uses of Apriori Algorithm**:\n",
        "###Market Basket Analysis:\n",
        "\n",
        "Apriori is commonly used in retail for market basket analysis, where the goal is to discover associations between products that are frequently purchased together. This information can be used for product placement, promotions, and inventory management.\n",
        "###Cross-Selling:\n",
        "\n",
        "It is used in e-commerce and online platforms to identify items that are often bought together, helping to suggest additional products to customers during their shopping experience.\n",
        "###Healthcare:\n",
        "\n",
        "In healthcare, Apriori can be applied to analyze patient records and identify co-occurring medical conditions or patterns of treatment.\n",
        "\n",
        "###Network Security:\n",
        "\n",
        "The algorithm can be used in network security to identify patterns of activities or behaviors that may indicate security threats.\n",
        "\n",
        "###Web Usage Mining:\n",
        "\n",
        "Apriori can be applied to analyze user navigation patterns on websites, helping to improve website design and user experience."
      ],
      "metadata": {
        "id": "8IYn79gWSz22"
      },
      "id": "8IYn79gWSz22"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35781c02-0ad1-4c52-9e82-256b88ba18eb",
      "metadata": {
        "id": "35781c02-0ad1-4c52-9e82-256b88ba18eb",
        "outputId": "ec62d9f5-b893-4f6a-e33d-a3146982396e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   support       itemsets\n",
            "0      0.6         (Beer)\n",
            "1      0.8        (Bread)\n",
            "2      0.6       (Diaper)\n",
            "3      0.6         (Milk)\n",
            "4      0.6  (Milk, Bread)\n",
            "  antecedents consequents  antecedent support  consequent support  support  \\\n",
            "0      (Milk)     (Bread)                 0.6                 0.8      0.6   \n",
            "1     (Bread)      (Milk)                 0.8                 0.6      0.6   \n",
            "\n",
            "   confidence  lift  leverage  conviction  zhangs_metric  \n",
            "0        1.00  1.25      0.12         inf            0.5  \n",
            "1        0.75  1.25      0.12         1.6            1.0  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lab009/.local/lib/python3.8/site-packages/mlxtend/frequent_patterns/fpcommon.py:109: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from mlxtend.frequent_patterns import apriori\n",
        "from mlxtend.frequent_patterns import association_rules\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "data = {'Transaction_ID': [1, 2, 3, 4, 5],\n",
        "        'Items': [['Milk', 'Bread', 'Diaper'],\n",
        "                  ['Beer', 'Milk', 'Bread', 'Eggs'],\n",
        "                  ['Beer', 'Coke', 'Diaper'],\n",
        "                  ['Beer', 'Bread', 'Diaper'],\n",
        "                  ['Milk', 'Bread', 'Coke']]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "oht = pd.get_dummies(df['Items'].apply(pd.Series).stack()).groupby(level=0).sum()\n",
        "\n",
        "frequent_itemsets = apriori(oht, min_support=0.5, use_colnames=True)\n",
        "\n",
        "print(frequent_itemsets)\n",
        "\n",
        "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
        "\n",
        "# Print association rules\n",
        "print(rules)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JTz7eIYEAYGM"
      },
      "id": "JTz7eIYEAYGM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "\n",
        "    return [\n",
        "        ['bread', 'milk'],\n",
        "        ['bread', 'diaper', 'beer', 'egg'],\n",
        "        ['milk', 'diaper', 'beer', 'cola'],\n",
        "        ['bread', 'milk', 'diaper', 'beer'],\n",
        "        ['bread', 'milk', 'diaper', 'cola']\n",
        "    ]\n",
        "\n",
        "def create_candidates(itemsets, k):\n",
        "    # Generate candidate itemsets of size k\n",
        "    candidates = []\n",
        "    for i in range(len(itemsets)):\n",
        "        for j in range(i + 1, len(itemsets)):\n",
        "            if itemsets[i][:k - 2] == itemsets[j][:k - 2]:\n",
        "                candidate = list(set(itemsets[i]) | set(itemsets[j]))\n",
        "                candidate.sort()\n",
        "                if candidate not in candidates:\n",
        "                    candidates.append(candidate)\n",
        "    return candidates\n",
        "\n",
        "def prune_candidates(candidates, prev_itemsets):\n",
        "    # Prune candidates that contain subsets of size k-1 not in the previous itemsets\n",
        "    pruned_candidates = []\n",
        "    for candidate in candidates:\n",
        "        subsets = [candidate[:i] + candidate[i + 1:] for i in range(len(candidate))]\n",
        "        if all(subset in prev_itemsets for subset in subsets):\n",
        "            pruned_candidates.append(candidate)\n",
        "    return pruned_candidates\n",
        "\n",
        "def apriori(data, min_support):\n",
        "    itemsets = [[item] for transaction in data for item in transaction]\n",
        "    frequent_itemsets = []\n",
        "    k = 2\n",
        "\n",
        "    while itemsets:\n",
        "        candidates = create_candidates(itemsets, k)\n",
        "        candidate_counts = {tuple(candidate): 0 for candidate in candidates}\n",
        "\n",
        "        for transaction in data:\n",
        "            for candidate in candidates:\n",
        "                if set(candidate).issubset(transaction):\n",
        "                    candidate_counts[tuple(candidate)] += 1\n",
        "\n",
        "        frequent_itemsets_k = [list(candidate) for candidate, count in candidate_counts.items() if count >= min_support]\n",
        "        frequent_itemsets.extend(frequent_itemsets_k)\n",
        "\n",
        "        itemsets = prune_candidates(create_candidates(frequent_itemsets_k, k + 1), frequent_itemsets_k)\n",
        "        k += 1\n",
        "\n",
        "    return frequent_itemsets\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data = load_data()\n",
        "    min_support = 3\n",
        "    result = apriori(data, min_support)\n",
        "    print(\"Frequent Itemsets:\")\n",
        "    for itemset in result:\n",
        "        print(itemset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvQ2xMO2SAuA",
        "outputId": "871f52c8-75b0-47ef-eae4-0453817aaa12"
      },
      "id": "jvQ2xMO2SAuA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets:\n",
            "['bread', 'milk']\n",
            "['bread']\n",
            "['bread', 'diaper']\n",
            "['diaper', 'milk']\n",
            "['milk']\n",
            "['beer', 'diaper']\n",
            "['diaper']\n",
            "['beer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FP growth**\n",
        "Using library"
      ],
      "metadata": {
        "id": "4zXouethKKfY"
      },
      "id": "4zXouethKKfY"
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.frequent_patterns import fpgrowth\n",
        "import pandas as pd\n",
        "\n",
        "dataset = pd.DataFrame({'A' : [1,1,0,1],'B' : [0,1,1,1],'C' : [1,1,0,1],'D' : [0,1,1,1]})\n",
        "freq_itemset = fpgrowth(dataset, min_support = 0.5, use_colnames = True)\n",
        "print(freq_itemset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0p15pCBAbKb",
        "outputId": "9817b265-45fd-4029-9ed7-73c28819433b"
      },
      "id": "m0p15pCBAbKb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    support      itemsets\n",
            "0      0.75           (C)\n",
            "1      0.75           (A)\n",
            "2      0.75           (D)\n",
            "3      0.75           (B)\n",
            "4      0.50        (D, C)\n",
            "5      0.75        (A, C)\n",
            "6      0.50        (A, B)\n",
            "7      0.50        (A, D)\n",
            "8      0.50     (A, B, C)\n",
            "9      0.50     (A, D, C)\n",
            "10     0.50     (A, B, D)\n",
            "11     0.50  (A, B, D, C)\n",
            "12     0.75        (B, D)\n",
            "13     0.50        (B, C)\n",
            "14     0.50     (D, B, C)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NlbusLnIAa_j"
      },
      "id": "NlbusLnIAa_j"
    },
    {
      "cell_type": "code",
      "source": [
        "# from mlxtend.preprocessing import TransactionEncoder\n",
        "# from mlxtend.frequent_patterns import fpgrowth\n",
        "\n",
        "# # Example usage:\n",
        "# transactions = [\n",
        "#     ['A', 'B', 'D'],\n",
        "#     ['B', 'C', 'E'],\n",
        "#     ['A', 'B', 'D', 'E'],\n",
        "#     ['B', 'E']\n",
        "# ]\n",
        "# min_support = 2\n",
        "\n",
        "# te = TransactionEncoder()\n",
        "# te_ary = te.fit(transactions).transform(transactions)\n",
        "# df = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "# frequent_itemsets = fpgrowth(df, min_support=min_support, use_colnames=True)\n",
        "\n",
        "# print(\"Frequent Itemsets:\", frequent_itemsets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGJ04tzxAyVo",
        "outputId": "2d2530d1-663b-456d-fb84-18c5d06a2f6f"
      },
      "id": "YGJ04tzxAyVo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "class FPNode:\n",
        "    def __init__(self, item, count, parent):\n",
        "        self.item = item\n",
        "        self.count = count\n",
        "        self.parent = parent\n",
        "        self.children = {}\n",
        "\n",
        "def build_tree(transactions, min_support):\n",
        "    header_table = {}\n",
        "\n",
        "    for transaction in transactions:\n",
        "        for item in transaction:\n",
        "            header_table[item] = header_table.get(item, 0) + 1\n",
        "\n",
        "    header_table = {k: v for k, v in header_table.items() if v >= min_support}\n",
        "\n",
        "    frequent_items = list(header_table.keys())\n",
        "    frequent_items.sort(key=lambda item: header_table[item], reverse=True)\n",
        "\n",
        "    root = FPNode(None, None, None)\n",
        "\n",
        "    for transaction in transactions:\n",
        "        sorted_items = [item for item in frequent_items if item in transaction]\n",
        "        insert_tree(sorted_items, root, header_table)\n",
        "\n",
        "    return root, header_table\n",
        "\n",
        "def insert_tree(items, node, header_table):\n",
        "    if items:\n",
        "        current_item = items[0]\n",
        "        if current_item in node.children:\n",
        "            child = node.children[current_item]\n",
        "        else:\n",
        "            child = FPNode(current_item, 0, node)\n",
        "            node.children[current_item] = child\n",
        "            if current_item in header_table:\n",
        "                update_header_table(header_table, child)\n",
        "\n",
        "        child.count += 1\n",
        "        insert_tree(items[1:], child, header_table)\n",
        "\n",
        "def update_header_table(header_table, node):\n",
        "    while node.parent is not None:\n",
        "        header_table[node.item].append(node)\n",
        "        node = node.parent\n",
        "\n",
        "def fp_growth(tree, header_table, prefix, frequent_itemsets, min_support):\n",
        "    for node in header_table.values():\n",
        "        new_frequent_set = prefix.copy()\n",
        "        new_frequent_set.add(node.item)\n",
        "        frequent_itemsets.append(new_frequent_set)\n",
        "\n",
        "        cond_pattern_base = []\n",
        "        while node is not None:\n",
        "            prefix_path = []\n",
        "            ascend_tree(node, prefix_path)\n",
        "            if prefix_path:\n",
        "                cond_pattern_base.append(prefix_path)\n",
        "            node = node.parent\n",
        "\n",
        "        cond_tree, cond_header_table = build_tree(cond_pattern_base, min_support)\n",
        "        if cond_header_table:\n",
        "            fp_growth(cond_tree, cond_header_table, new_frequent_set, frequent_itemsets, min_support)\n",
        "\n",
        "def ascend_tree(node, prefix_path):\n",
        "    if node.parent is not None:\n",
        "        prefix_path.append(node.item)\n",
        "        ascend_tree(node.parent, prefix_path)\n",
        "\n",
        "# Example usage:\n",
        "transactions = [\n",
        "    ['A', 'B', 'D'],\n",
        "    ['B', 'C', 'E'],\n",
        "    ['A', 'B', 'D', 'E'],\n",
        "    ['B', 'E']\n",
        "]\n",
        "min_support = 2\n",
        "\n",
        "root, header_table = build_tree(transactions, min_support)\n",
        "frequent_itemsets = []\n",
        "fp_growth(root, header_table, set(), frequent_itemsets, min_support)\n",
        "\n",
        "print(\"Frequent Itemsets:\", frequent_itemsets)\n"
      ],
      "metadata": {
        "id": "4vVo2TEhA1Ls"
      },
      "id": "4vVo2TEhA1Ls",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}